{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# macro do ipython para rederizar o matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "# numpy é uma biblioteca de python que \n",
    "# nos permite fazer operações matriciais e vetoriais\n",
    "# facilmente, e eficientemente (até um certo tamanho)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "Dar alguns exemplos de ensembles no contexto de classificação textual.\n",
    "\n",
    "### Carregando conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english...n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import  cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# carregando conjunto de dados\n",
    "train_20ng = fetch_20newsgroups(subset='train', shuffle=True, remove=('headers', 'quotes', 'footers'))\n",
    "test_20ng = fetch_20newsgroups(subset='test', shuffle=True, remove=('headers', 'quotes', 'footers'))\n",
    "\n",
    "# Vamos criar o nosso fluxo de execução\n",
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    Perceptron(random_state = 0)\n",
    ")\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    5.3s remaining:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english...n_iter=5, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
       "      verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.693276526757\n",
      "Teste F1: 0.618027\n"
     ]
    }
   ],
   "source": [
    "print(valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging de Perceptrons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english...estimators=50, n_jobs=-1, oob_score=True,\n",
       "         random_state=None, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    BaggingClassifier(base_estimator=Perceptron(random_state = 0), n_estimators=50, n_jobs=-1, oob_score=True)\n",
    ")\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baggin de Perceptrons\n",
      "OOB Score:  0.764804666785\n",
      "Valid. F1:  0.749541995122\n",
      "Teste F1: 0.674578\n"
     ]
    }
   ],
   "source": [
    "print(\"Baggin de Perceptrons\")\n",
    "print(\"OOB Score: \", pipe.steps[-1][-1].oob_score_)\n",
    "print(\"Valid. F1: \", valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble de Árvores de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   24.9s remaining:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   25.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Árvore de Decisão\n",
      "Valid. F1:  0.47155917936\n",
      "Teste F1: 0.429698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    DecisionTreeClassifier()\n",
    ")\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)\n",
    "\n",
    "print(\"Árvore de Decisão\")\n",
    "print(\"Valid. F1: \",valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   35.9s remaining:   53.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   36.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "OOB Score:  0.65432207884\n",
      "Valid. F1:  0.650516480409\n",
      "Teste F1: 0.596571\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    RandomForestClassifier(n_jobs=-1, n_estimators=100, oob_score=True)\n",
    ")\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=-1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"OOB Score: \", pipe.steps[-1][-1].oob_score_)\n",
    "print(\"Valid. F1: \", valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=200, n_jobs=-1)\n",
    ")\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)\n",
    "\n",
    "print(\"Bagging de Árvores\")\n",
    "print(\"Valid. F1: \", valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voto majoritário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   53.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voto\n",
      "Valid. F1:  0.754733592708\n",
      "Teste F1: 0.685985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Vamos utilizar os melhores modelos que vimos até então.\n",
    "# São eles: SVM, Bagging de Perceptrons e lreg\n",
    "clfs = [('svm', LinearSVC(C=0.5, dual=True)),\n",
    "        ('bag', BaggingClassifier(base_estimator=Perceptron(random_state = 0), n_estimators=50, n_jobs=-1)),\n",
    "        ('lreg', LogisticRegression(C=0.297302, random_state=0, dual=True, n_jobs=-1))]\n",
    "\n",
    "vote = VotingClassifier(estimators=clfs)\n",
    "\n",
    "pipe = make_pipeline(\n",
    "    CountVectorizer(stop_words='english', min_df=2),\n",
    "    TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=True),\n",
    "    vote\n",
    ")\n",
    "\n",
    "valid_score = cross_val_score(pipe, train_20ng.data, train_20ng.target,\n",
    "                              scoring='f1_macro', cv=cv, n_jobs=1, verbose=1)\n",
    "pipe.fit(train_20ng.data, train_20ng.target)\n",
    "print(\"Voto\")\n",
    "print(\"Valid. F1: \",valid_score.mean())\n",
    "print(\"Teste F1: %f\" % (f1_score(test_20ng.target, pipe.predict(test_20ng.data), average='macro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
