{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# macro do ipython para rederizar o matplotlib inline\n",
    "%matplotlib inline\n",
    "\n",
    "# numpy é uma biblioteca de python que \n",
    "# nos permite fazer operações matriciais e vetoriais\n",
    "# facilmente, e eficientemente (até um certo tamanho)\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "\n",
    "O objetivo desse jupyter notebook é complementar a aula teórica com uma perspectiva prática do svm.\n",
    "Vamos mostrar os efeitos do hiperparâmetro do SVM. Vamos dar um exemplo de classificação textutal utilizando o svm.\n",
    "\n",
    "### Classificação textual com SVM\n",
    "\n",
    "Vamos utilizar o conjunto de dados 20newsgroups disponível no scikit-learn. Esse conjunto de dados possui aproximadamente 18000 newsgroups posts categorizados em 20 tópicos dividos em dois conjuntos: um para treino e outro para teste (em outras palavras, para avaliação de desempenho do modelo). A divisão entre conjunto de treino e teste basedo em mensagens postadas antes e depois uma data específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train_20ng = fetch_20newsgroups(subset='train')\n",
    "test_20ng = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar como são os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: guykuo@carson.u.washington.edu (Guy Kuo)\n",
      "Subject: SI Clock Poll - Final Call\n",
      "Summary: Final call for SI clock reports\n",
      "Keywords: SI,acceleration,clock,upgrade\n",
      "Article-I.D.: shelley.1qvfo9INNc3s\n",
      "Organization: University of Washington\n",
      "Lines: 11\n",
      "NNTP-Posting-Host: carson.u.washington.edu\n",
      "\n",
      "A fair number of brave souls who upgraded their SI clock oscillator have\n",
      "shared their experiences for this poll. Please send a brief message detailing\n",
      "your experiences with the procedure. Top speed attained, CPU rated speed,\n",
      "add on cards and adapters, heat sinks, hour of usage per day, floppy disk\n",
      "functionality with 800 and 1.4 m floppies are especially requested.\n",
      "\n",
      "I will be summarizing in the next two days, so please add to the network\n",
      "knowledge base if you have done the clock upgrade and haven't answered this\n",
      "poll. Thanks.\n",
      "\n",
      "Guy Kuo <guykuo@u.washington.edu>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_20ng.data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados são textos puros dos post contendo algums metadados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_20ng.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como já fora mencionado, há 20 categorias distintas para os postes.\n",
    "\n",
    "Ok!! Mas como a gente faz o algoritmo entender esses textos? A gente simplesmente passa para o algoritmos os dados dessa forma? Os modelos lineares, assim como svm, não precisam trabalhar com valores numéricos contínuos e numa mesma escala? \n",
    "\n",
    "De fato, nós precisamos transformar esses dados textuais em numéricos e, além disso, precisamos deixá-lo em uma mesma escala.\n",
    "\n",
    "Não sei se vocês se lembram, mas na aula demos um exemplo de problema com texto e os atributos que sugerimos foram a frequência que cada termo/palavra ocorreu em um dado post/documento.\n",
    "\n",
    "Essa um forma simples e eficaz de representar dados textuais na forma vetorial. E é conhecido como **bag-of-words**, em bom português ***saco de palavras***.\n",
    "\n",
    "O scikit-learn nos oferece um modo bem simples de transforma dados textutais em **bag-of-words**, então vamos lá transformar esses dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. de Exmplos de Treino: 11314; N. de Atributos: 130107\n",
      "N. de Exmplos de Teste: 7532; N. de Atributos: 130107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# transforma dados textuais em uma presentação vetorial usando\n",
    "# bag-of-words\n",
    "vec = CountVectorizer()\n",
    "\n",
    "X_train = vec.fit_transform(train_20ng.data)\n",
    "y_train = train_20ng.target\n",
    "\n",
    "X_test = vec.transform(test_20ng.data)\n",
    "y_test = test_20ng.target\n",
    "\n",
    "print(\"N. de Exmplos de Treino: %d; N. de Atributos: %d\" % X_train.shape)\n",
    "print(\"N. de Exmplos de Teste: %d; N. de Atributos: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nossa, essa transformação gerou 130 mil atributos. É coisa demais!! Isso é por causa da grande quantidade de palavras distintas que podem existir em um vocabulário. Além disso, a maioria dos valores dos atributos para cada exemplo é zero (dados esparsos), pois a maioria das palavras não acontecem em uma grande quantidade de postes. Não vamos aprofundar muito nisso agora, mas tem formas de diminuir essa quantidade de atributos, pois nem sempre mais atributos é bom.\n",
    "\n",
    "Agora que nós já temos os dados em uma representação que o algoritmo entendi, nós iremos rodar o SVM com kernel linear.\n",
    "\n",
    "Mas, vai dar certo isso? Os dados são linearmente separáveis? \n",
    "\n",
    "Então, dados textuais nesse tipo de representação bag-of-words são conhecidos por serem linearmente separáveis, portanto, uma boa posta é utilizar métodos lineares para esse tipo de problema. E de fato, o SVM linear é um método estado-da-arte para problemas que envolvem classificação textual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=123, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(random_state=123)\n",
    "\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos avaliar o desempenho do modelo aprendido pelo SVM. Geralmente em classificação de texto é utilizado como métrica de avaliação a métrica F1, que é a média harmonica entre precisão e revocação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78584705257567711"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nada mal para uma primeira tentativa. Lembram-se do hiperpârametro **C**? \n",
    "\n",
    "Vamos bricar um pouco com ele para vermos se conseguimos uma melhoria em nosso resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77668613913967077"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=10, random_state=123).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.800849707912905"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.1, random_state=123).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81704726500265534"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.01, random_state=123).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso primeiro teste foi C=1, o método tinha afroxado a restrição permitindo erro na \"rua\". Quando aumentamos para 10 o valor de C, vimos que houve uma degração um pouco maior na performance do modelo. Isso nos da evidências que afroxar a restrição não é o caminho para melhorar a predição do modelo. Desse modo, nós tentamos diminuir o valor de C, desse modo, deixando as retrições mais rígidas e vimos que nessa direção tivemos um aumento no desempenho preditivo de nosso modelo.\n",
    "\n",
    "Escolhemnos essa maneira de calibrar os parâmetros para elucidar o impacto do hiperparâmetro no desempenho preditivo do modelo aprendido, todavia, essa não é a melhor forma de calibrar o hiperparâmetro de um método. É melhor usar métodos menos tendênciosos para escolher os valores desses hiperparâmetros, tal como validação cruzada que veremos na aula 4 desse curso.\n",
    "\n",
    "Além de calibrar os hiperparâmetros podemos melhorar os atributos que estamos dando para nosso métodos, veremos mais isso em aulas posteriores, porém vamos dar um exemplo agora. \n",
    "\n",
    "### Stopwords\n",
    "\n",
    "Stopwords são palavras cuja a ocorrência é demasiada e não ascrecenta nenhum ou pouco valor discriminativo ao método. Por exemplo, artigos e preposições (a, o, um, uma, todavia, contudo, porém, etc...). Desse modo, vamos remover essas palavras de nosso vocabulários e ver se conseguimos melhorar o modelo em alguma coisa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. de Exmplos de Treino: 11314; N. de Atributos: 129796\n",
      "N. de Exmplos de Teste: 7532; N. de Atributos: 129796\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train = vec.fit_transform(train_20ng.data)\n",
    "y_train = train_20ng.target\n",
    "\n",
    "X_test = vec.transform(test_20ng.data)\n",
    "y_test = test_20ng.target\n",
    "\n",
    "print(\"N. de Exmplos de Treino: %d; N. de Atributos: %d\" % X_train.shape)\n",
    "print(\"N. de Exmplos de Teste: %d; N. de Atributos: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82342007434944253"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.01, random_state=123).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Só isso melhorou o modelo, mesmo que pouco! Vamos remover também as palavras que ocorrem muito raramente no conjunto de treino. Vamos dizer que as palavras que aparecem ao menos em 2 posts devem permanecer, se aparecerem menos serão eliminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N. de Exmplos de Treino: 11314; N. de Atributos: 56126\n",
      "N. de Exmplos de Teste: 7532; N. de Atributos: 56126\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(stop_words='english', min_df=2)\n",
    "\n",
    "X_train = vec.fit_transform(train_20ng.data)\n",
    "y_train = train_20ng.target\n",
    "\n",
    "X_test = vec.transform(test_20ng.data)\n",
    "y_test = test_20ng.target\n",
    "\n",
    "print(\"N. de Exmplos de Treino: %d; N. de Atributos: %d\" % X_train.shape)\n",
    "print(\"N. de Exmplos de Teste: %d; N. de Atributos: %d\" % X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso fez com que diminuíssimos o número de atributos de 129mil para 56mil. Além disso, talvez melhorar nosso poder preditivo, ainda ajudaremos o algoritmo a aprender mais rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82262347318109397"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC(C=0.01, random_state=123).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É... acho que mudou nada, porém o algoritmo rodou bem mais rápido :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desempenho das Formulações\n",
    "\n",
    "Na aula eu toquei rapidamente no assunto da forma Primal e Dual do problema de otimização do SVM quando estava falando sobre os Kernels. Além das diferenças na formulação permitir o uso de Kernels (no caso da formulação Dual), é importante também levar em consideração essas diferenças na escolha da formulação no que diz respeiro desempenho computacional do algoritmo.\n",
    "\n",
    "Vamos recapitular a forma primal:\n",
    "\n",
    "$min\\ \\frac{1}{2}||w||^2$\n",
    "\n",
    "$sujeito\\ a\\ y_i(w \\cdot x_i + b) \\geq 1$\n",
    "\n",
    "\n",
    "Essa é formulinha normalzinha e bonitinha! Podemos notar que o processo de minimização da mesma apenas depende de **w**, e **w** é um vetor com dimensões dependentes do número de atributos no conjunto de dados, ou seja $w \\in R^d$. Isso implica em que a formulação primal é uma boa escolha quando temos muito menos atributos que exemplos de treino.\n",
    "\n",
    "Já formulação dual depende dos exemplos de treino, como pode ser visto na equação a seguir, além disso $a_i \\in R^N$:\n",
    "\n",
    "\n",
    "$\\min\\ \\sum_{ij} \\alpha_i\\alpha_jy_iy_j(x_i^T \\cdot x_j)$\n",
    "\n",
    "$sujeito\\ a\\ y_i(\\sum_{i} \\alpha_iy_i(x_i^T \\cdot x_j) + b) \\geq 1$\n",
    "\n",
    "Isso implica em que a formulação dual é preferida quando temos muito menos exemplos do que atributos no conjunto de treino. Por exemplo, a formulação dual seria uma boa escolha nesse problema de classificação onde tínhamos 56k atributos e apenas 11k exemplos de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.93 s per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82262347318109397"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit svm = LinearSVC(C=0.01, random_state=123, dual=True).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 58.8 s per loop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82262347318109397"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit svm = LinearSVC(C=0.01, random_state=123, dual=False).fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "f1_score(y_test, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note que a formulação primal para esse problema demora muitíssimo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
