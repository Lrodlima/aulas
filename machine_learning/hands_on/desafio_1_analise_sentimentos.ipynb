{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conjunto de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reviews = np.loadtxt(\"data/analise-sent/yelp_reviews_no_score.txt\", delimiter='\\n', dtype=str)\n",
    "sentiment = np.loadtxt(\"data/analise-sent/yelp_reviews_so_score.txt\", dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de Sentimentos\n",
    "\n",
    "Nós estamos interessados em predizer o sentimento dos tweet a partir de seu contéudo. Portanto, devemos construir um modelo que seja capaz de classificar o sentimento (empty, sadness, enthisuasm, neutral) de um tweet a partir de seu texto.\n",
    "\n",
    "### Desafio\n",
    "\n",
    "Você deve a paritr dos conhecimentos adquiridos nas aula teórica, e seguindo os exemplos de classificação de texto exibidos em alguns notebooks: \n",
    "- machine_learning/aula_01/svm.ipynb\n",
    "- machine_learning/aula_02/naive_bayes.ipynb\n",
    "- machine_learning/aula_03/selecao_validacao.ipynb\n",
    "\n",
    "Construir um classificador capaz de predizer o sentimento de um dado tweet. Você deve utilizar tentar utilzar todo pipeline do scikit-learn para transformar os dados, selecionar e treinar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Dividir conjunto de dados em treino e teste\n",
    "\n",
    "# TODO: Construir pipeline para execução como em machine_learning/aula_03/selecao_validacao.ipynb \n",
    "\n",
    "# TODO: Testar vários alogirtmo para classificação do sentimento (análise de sentimentos) de tweets\n",
    "# Ex: LinearSVC, Naïve Bayes, RandomForest, SGB, Regressão Logística, Perceptron, ensembles...\n",
    "# Utilizar as técnicas de seleção de modelo vista em machine_learning/aula_03/selecao_validacao.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriquecendo os dados com NLTK e SentiWordNet\n",
    "\n",
    "[NLTK](http://www.nltk.org/) é uma plataforma criar programas em Python para trabalhar com dados de linguagem humana. Ela provê interfaces fáceis para mais de 50 corpus textuais e recursos léxicos tal como WordNet, juntamente com bibliotecas para processamente textual para classificação, tokenização, stemming, tagging, parsing, e semantica.\n",
    "\n",
    "WordNet nos prove uma interface, através do NLTK, para fazermos análise léxicas (descubrir se um termo é adjetivo, substantivo entre outros). O WordNet possui um dicionário de sentimentos, o SentiWordNet. Com isso conseguimos dar mais informações para o algoritmo de aprendizado e assim, podemos (talvez) aumentar seu poder preditivo.\n",
    "\n",
    "Vamos ver um exemplo de uso desses recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('happy.a.01'),\n",
       " SentiSynset('felicitous.s.02'),\n",
       " SentiSynset('glad.s.02'),\n",
       " SentiSynset('happy.s.04')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carregando a biblioteca do SentiWordNet através do nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "\n",
    "happy = swn.senti_synsets('happy', 'a')\n",
    "list(happy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos pegar a primeira ocorrência ```SentiSynset('happy.a.01')``` e destiricá-la:\n",
    "\n",
    "- happy = palavra que nós precisamos do score\n",
    "- a = classe gramatical (i.e., adjetivo, substantivo...)\n",
    "- '01' = Uso (01 para o uso mais comum e um número mais alto indica baixo uso da palavra)\n",
    "\n",
    "Com isso em mente, podemos ver que ```swn.senti_synsets('happy', 'a')``` busca por formas de usado da palavra 'happy' como adjetivo, e retorna o resultado ordenado pelo uso mais comum.\n",
    "\n",
    "As classes gramaticais suportadas são:\n",
    "\n",
    "- n - NOUN (substantivo)\n",
    "- v - VERB (verbo)\n",
    "- a - ADJECTIVE (adjetivo)\n",
    "- s - ADJECTIVE SATELLITE (?) \n",
    "- r - ADVERB (adverbio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_score(happy):  0.875\n",
      "neg_score(happy):  0.0\n",
      "pos_score(happily):  0.5\n",
      "neg_score(happily):  0.25\n"
     ]
    }
   ],
   "source": [
    "word = 'happy'\n",
    "# score negativo para o advérbio happily\n",
    "print(\"pos_score(%s): \" % word, list(swn.senti_synsets(word, 'a'))[0].pos_score())\n",
    "# score negativo para o advérbio happily\n",
    "print(\"neg_score(%s): \" % word, list(swn.senti_synsets(word, 'a'))[0].neg_score())\n",
    "\n",
    "word = 'happily'\n",
    "# score negativo para o advérbio happily\n",
    "print(\"pos_score(%s): \" % word, list(swn.senti_synsets(word, 'r'))[0].pos_score())\n",
    "# score negativo para o advérbio happily\n",
    "print(\"neg_score(%s): \" % word, list(swn.senti_synsets(word, 'r'))[0].neg_score())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso não a palavra não seja da classe gramativa em questão ou então não exista o método retorna uma lista vazia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# happy é adjetivo e não um advérbio\n",
    "list(swn.senti_synsets('happy', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia então é enriquecer seu modelo com essas infomações. Por exemplo, ao invés de utilizar frequência de termo, você pode utilizar quão positivo é aquele termo e quão negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse\n",
    "\n",
    "class CountSentimentTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cv = CountVectorizer(stop_words = 'english')\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        def sentiment(term):\n",
    "            \"\"\"Para cada termo é recuperado quão positivo ou negativo ele é\n",
    "            de acordo com o SentiWordNet\"\"\"\n",
    "            part_of_speech = ['a', 'r', 'v']\n",
    "            pos = neg = obj = 0\n",
    "            \n",
    "            try:\n",
    "                for p in part_of_speech:\n",
    "                    results = list(swn.senti_synsets(term, p))\n",
    "                    if results != []:\n",
    "                        pos += results[0].pos_score()\n",
    "                        neg += results[0].neg_score()\n",
    "                        obj += results[0].obj_score()\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "            # é retornado um array com os scores para cada sentimento            \n",
    "            return np.array([pos, neg, obj])\n",
    "    \n",
    "        \n",
    "        # fitamos o CountVectorizer para extração dos termos\n",
    "        self.cv.fit(X, y)\n",
    "        \n",
    "        # para cada termo, nós obtemos a intensidade de seus sentimentos\n",
    "        # utilizando o método sentiment acima.\n",
    "        indices = [int(index) for term, index in self.cv.vocabulary_.items()]\n",
    "        terms = np.array([term for term, index in self.cv.vocabulary_.items()])\n",
    "        self.sent = np.array([sentiment(term) for term, index in self.cv.vocabulary_.items()])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # transformando os dados de acordo com\n",
    "        # CountVectorizer aprendido\n",
    "        X_t = self.cv.transform(X)\n",
    "        \n",
    "        # Multiplicamos a ocorrencia dos termos pela intensidade\n",
    "        # de cada sentimento (positivo e negativo)\n",
    "        X_pos = X_t.multiply(self.sent[:, 0])\n",
    "        X_neg = X_t.multiply(self.sent[:, 1])\n",
    "        X_obj = X_t.multiply(self.sent[:, 2])\n",
    "        \n",
    "        # Concatenamos os atributos enriquecidos e os atributos originais\n",
    "        return scipy.sparse.hstack((X_pos, X_neg, X_t)).tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    9.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913333333333 {'linearsvc__C': 1.0}\n",
      "0.922496725487\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  24 out of  24 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.912333333333 {'linearsvc__C': 1.0}\n",
      "0.921998049951\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(reviews, sentiment, test_size = 0.4, random_state = 0)\n",
    "\n",
    "\n",
    "csent = CountSentimentTransformer()\n",
    "# Criamos um pipeline com nosso CountSentiment, Normalizer e um LinearSVC\n",
    "# Quando damos um fit no pipeline ele vai passando o resultados dos transformers em cadeia.\n",
    "# Ou seja, primeiramente é executado o fit_transform do CounSentimentTransformer, os dados\n",
    "# transformados por esse transformer é passado para o seguinte transformer no pipeline,\n",
    "# o Normalizer, esse por sua vez transforma os vetores em vetores unitários e passa\n",
    "# para o LinearSVC os dados transformados que por sua vez é treinado.\n",
    "# Quando o predict é utilizado esse processo de transformação também é executado para o\n",
    "# dado sendo testado.\n",
    "pipe = make_pipeline(csent, Normalizer(), LinearSVC())\n",
    "cv = GridSearchCV(pipe, {'linearsvc__C': 2. ** np.arange(-3, 5, 1)},  verbose=1, n_jobs=-1)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, cv.best_params_)\n",
    "print(f1_score(cv.predict(X_test), y_test, average = 'macro'))\n",
    "\n",
    "\n",
    "pipe = make_pipeline(CountVectorizer(stop_words = 'english'), Normalizer(), LinearSVC())\n",
    "cv = GridSearchCV(pipe, {'linearsvc__C': 2. ** np.arange(-3, 5, 1)}, verbose=1, n_jobs=-1)\n",
    "cv.fit(X_train, y_train)\n",
    "print(cv.best_score_, cv.best_params_)\n",
    "print(f1_score(cv.predict(X_test), y_test, average = 'macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
