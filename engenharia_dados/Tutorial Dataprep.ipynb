{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "O objetivo desse tutorial é apresentar técnicas para preparação de dados utilizando pyspark.\n",
    "\n",
    "## PySpark\n",
    "O PySpark é uma biblioteca de Spark para Python.\n",
    "\n",
    "## Antes de continuar\n",
    "O arquivo **/home/class/Desktop/hands-on/all_hadoop.sh** será utilizado para controlar os serviços do hadoop, hdfs e hive.\n",
    "Para continuar execute o comando abaixo:\n",
    "```bash\n",
    "sh /home/class/Desktop/hands-on/all_hadoop.sh start\n",
    "```\n",
    "\n",
    "Ao finalizar, execute o comando:\n",
    "```bash\n",
    "sh /home/class/Desktop/hands-on/all_hadoop.sh stop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando uma pasta, carregando arquivos e listando conteúdo no HDFS\n",
    "O HDFS é o sistema de arquivos distribuído do ecossistema hadoop. Ele será o repositório para armazenamento dos arquivos que serão processados pelo Spark.\n",
    "\n",
    "Primeiramente, vamos alterar algumas permissões do HDFS.\n",
    "```bash\n",
    "su hdfs\n",
    "\n",
    "hdfs dfs -chmod 777 /user\n",
    "\n",
    "exit\n",
    "```\n",
    "\n",
    "Agora fazemos o upload dos arquivos para o HFDS.\n",
    "```bash\n",
    "hdfs dfs -mkdir /user/files\n",
    "\n",
    "# Lembre-se de alterar \"sample\" pelo nome do arquivo que será carregado\n",
    "hdfs dfs -put sample.csv /user/files/sample.csv # Carregando arquivo para o HDFS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando pyspark para trabalhar sobre os arquivos\n",
    "\n",
    "O código a baixo é um exemplo de como trabalhar com arquivos do HDFS no pyspark.\n",
    "```python\n",
    "import pyspark\n",
    "\n",
    "# Cria uma sessão spark\n",
    "spark = pyspark.sql.SparkSession.builder.master(\"local\").appName(\"class\").getOrCreate()\n",
    "\n",
    "# Lê o csv salvo no hdfs\n",
    "df = spark.read.csv(\"hdfs://localhost/user/files/sample.csv\", header=True)\n",
    "\n",
    "# Imprime a cabeçalho arquivo\n",
    "print(df)\n",
    "DataFrame[nome: string, idade: string, profissao: string]\n",
    "```\n",
    "\n",
    "Vamos para alguns exemplos de tratamento desses dados:\n",
    "\n",
    "#### Mudando tipo de dado de uma coluna\n",
    "\n",
    "Perceba que a coluna \"idade\" esta com tipo \"string\". O seguinte comando permite alterar o tipo da coluna.\n",
    "\n",
    "```python\n",
    "df = df.withColumn(\"idade\", df[\"idade\"].cast(\"int\"))\n",
    "```\n",
    "*Esse mesmo comando pode ser utilizado para criar uma coluna, apenas mude o primeiro parâmetro*\n",
    "\n",
    "#### Estatísticas de colunas numéricas\n",
    "\n",
    "O seguinte comando pode ser usado para gerar estatísticas da base. Nesse caso, ele irá retornar informações sobre todos as colunas numéricas. Isso pode ajudar a avaliar alguns problemas, por exemplo, o valor mínimo \"1\" para idade.\n",
    "\n",
    "```python\n",
    "df.describe().show()\n",
    "+-------+------------------+\n",
    "|summary|             idade|\n",
    "+-------+------------------+\n",
    "|  count|                 6|\n",
    "|   mean|29.166666666666668|\n",
    "| stddev|15.904925861715503|\n",
    "|    min|                 1|\n",
    "|    max|                43|\n",
    "+-------+------------------+\n",
    "```\n",
    "\n",
    "#### Removendo registros duplicados\n",
    "\n",
    "O comando dropDuplicates, remove linhas duplicadas do dataframe.\n",
    "\n",
    "```python\n",
    "# Removendo duplicados considerando o match em todas as colunas.\n",
    "df.dropDuplicates().show()\n",
    "+------+-----+-------------+                                                    \n",
    "|  nome|idade|    profissao|\n",
    "+------+-----+-------------+\n",
    "| maria|    1|      gerente|\n",
    "| maria|   37|      gerente|\n",
    "| paulo|   25|         null|\n",
    "|tereza|   26|   jornalista|\n",
    "| pedro|   43|desenvolvedor|\n",
    "+------+-----+-------------+\n",
    "```\n",
    "Se sabemos que a coluna nome é única, então maria parece estar duplicada. O seguinte comando pode ser utilizado para remover linhas duplicadas baseado em colunas específicas.\n",
    "\n",
    "```python\n",
    "# Removendo duplicados considerando o match em todas as colunas.\n",
    "df.dropDuplicates([\"nome\", \"profissao\"]).show()\n",
    "+------+-----+-------------+                                                    \n",
    "|  nome|idade|    profissao|\n",
    "+------+-----+-------------+\n",
    "| pedro|   43|desenvolvedor|\n",
    "| maria|    1|      gerente|\n",
    "| paulo|   25|         null|\n",
    "|tereza|   26|   jornalista|\n",
    "+------+-----+-------------+\n",
    "```\n",
    "Ops, maria possui apenas 1 ano de idade? rsrsrs\n",
    "O comando manteve apenas o primeiro registro da base. Uma solução seria a seguinte:\n",
    "\n",
    "```python\n",
    "# Agrupando dataframe com base nas informações de algumas colunas e retornando o máximo da segunda base.\n",
    "df = df.groupby([\"nome\", \"profissao\"]).max()\n",
    "# Renomeando coluna do dataframe\n",
    "df = df.withColumnRenamed(\"max(idade)\", \"idade\")\n",
    "\n",
    "df.show()\n",
    "+------+-------------+----------+\n",
    "|  nome|    profissao|     idade|\n",
    "+------+-------------+----------+\n",
    "| pedro|desenvolvedor|        43|\n",
    "| maria|      gerente|        37|\n",
    "| paulo|         null|        25|\n",
    "|tereza|   jornalista|        26|\n",
    "+------+-------------+----------+\n",
    "```\n",
    "\n",
    "#### Salvando arquivos\n",
    "Depois dos tratamentos realizados, vamos salvar o arquivo tratado.\n",
    "\n",
    "```python\n",
    "df.write.csv('hdfs://localhost/user/files/sample_treated.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio\n",
    "Faça os tratamentos necessários sobre a base de dados coletada a partir do IBGE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
